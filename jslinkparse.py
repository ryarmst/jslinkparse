#!/usr/bin/env python

# A simple Python 3 script to organize JS Link Finder (Burp Extension) output for further testing. 
# NOTE: probably does not handle many "edge" cases well

## TODO ##
# Make -i include wanted extensions only
# Make -e exclude unwanted extensions

import re
import os
import sys
import argparse

__version__ = 0.01

def main(arguments):

	parser = argparse.ArgumentParser(
		description=__doc__,
		formatter_class=argparse.RawDescriptionHelpFormatter)
	parser.add_argument('infile', help="Input file", type=argparse.FileType('r'))
	#parser.add_argument('outfile', help="Output file",default=sys.stdout, type=argparse.FileType('w')) # would rather just stdout
	#parser.add_argument('-s', help="Sort results (directories, full URLs, JS/CSS, etc.)", action='store_true', default=0) #naaa

	args = parser.parse_args(arguments)

	# Declaration of lists - should make more dynamic
	fullUrls = []
	directories = []
	scripts = []
	paths = []
	images =[]

	for lines in args.infile:
		# Skip first lines generated by JS parsing tool
		if (re.search("Burp JS LinkFinder", lines) or (re.search("Copyright (c) 2019 Frans", lines))):
			continue
		# Skip the source JS files
		if (re.search("\[+\] ", lines)):
			continue
		# Parse full URLs
		if (re.search("\t[0-9]+ - ", lines) and re.search(":\/\/", lines)):
			fullUrls.append(lines[(re.search(" - ", lines).start()+3):]) # lol deal with it
			continue
		# Parse Protocol Relative links and include with URLs
		if (re.search("\t[0-9]+ - \/\/", lines)):
			fullUrls.append(lines[(re.search(" - \/\/", lines).start()+3):])
			continue
		# Parse directories
		if ((re.search("\t[0-9]+ - ", lines)) and (re.search("\/\n", lines))):
			directories.append(lines[(re.search(" - ", lines).start()+3):]) 
			continue
		# Parse JavaScript and CSS
		if (re.search("\t[0-9]+ - ", lines)) and (re.search("\.js\n", lines) or (re.search("\.css\n", lines))):
			scripts.append(lines[(re.search(" - ", lines).start()+3):])
			continue
		# Parse images
		if (re.search("\t[0-9]+ - ", lines)) and (re.search("\.png\n", lines) or (re.search("\.jpg\n", lines)) or (re.search("\.jpeg\n", lines)) or (re.search("\.svg\n", lines)) or (re.search("\.gif\n", lines))): # Will make this predefined constant list at some point
			images.append(lines[(re.search(" - ", lines).start()+3):])
			continue
		# For everything else
		if (re.search("\t[0-9]+ - ", lines)):
			paths.append(lines[(re.search(" - ", lines).start()+3):])

	# Sort lists and remove duplicates
	fullUrls = sorted(list(dict.fromkeys(fullUrls)))
	directories = sorted(list(dict.fromkeys(directories)))
	paths = sorted(list(dict.fromkeys(paths)))
	scripts = sorted(list(dict.fromkeys(scripts)))
	images = sorted(list(dict.fromkeys(images)))

	# Print results
	print("----------URLs:----------\n")
	for x in fullUrls:
		print(x, end='') # extra crlf must come from the data - this fixes it
	print("\n----------Directories:----------\n")
	for x in directories:
		print(x, end='')
	print("\n----------Paths----------\n")
	for x in paths:
		print(x, end='')
	print("\n----------Scripts:----------\n")
	for x in scripts:
		print(x, end='')
	print("\n----------Images:----------\n")
	for x in images:
		print(x, end='')

		# TODO
		# Parse custom extensions only

if __name__ == '__main__':
	sys.exit(main(sys.argv[1:]))
